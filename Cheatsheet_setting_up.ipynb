{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#setting up my usual packages\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import pylab as pl\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns;\n",
    "\n",
    "try: \n",
    "    import urllib2 as urllib\n",
    "except ImportError:\n",
    "    import urllib.request as urllib\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cusp/rxl204/PUIdata\n"
     ]
    }
   ],
   "source": [
    "PUIdata = os.getenv('PUIDATA')\n",
    "print (PUIdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State data source in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File in place, proceed!\n"
     ]
    }
   ],
   "source": [
    "#download files using curl\n",
    "if not os.path.isfile(PUIdata + \"/BORO_zip_files_csv/MN.csv\"):\n",
    "    print('Downloading...')\n",
    "    os.system('curl -O https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyc_pluto_16v2%20.zip')\n",
    "    os.system('mv nyc_pluto_16v2%20.zip ' + PUIdata)\n",
    "    os.system('unzip ' + PUIdata + '/nyc_pluto_16v2%20.zip -d ' + PUIdata)\n",
    "    if os.path.isfile(PUIdata + \"/BORO_zip_files_csv/MN.csv\"):\n",
    "        print('File in place, proceed!')\n",
    "else:\n",
    "    print('File in place, proceed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File in place, proceed!\n"
     ]
    }
   ],
   "source": [
    "#using wget (web get)\n",
    "url = 'https://data.cityofnewyork.us/api/views/rgfe-8y2z/rows.csv?accessType=DOWNLOAD'\n",
    "filename = 'LL84_2013.csv'\n",
    "\n",
    "if not os.path.isfile(PUIdata + '/' + filename):\n",
    "    print('Downloading...')\n",
    "    os.system('wget ' + url)\n",
    "    os.system('mv rows.csv?accessType=DOWNLOAD ' + filename)\n",
    "    os.system('mv ' + filename + ' ' + PUIdata)\n",
    "    if os.path.isfile(PUIdata + '/' + filename):\n",
    "        print('File in place, proceed!')\n",
    "else:\n",
    "    print('File in place, proceed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/anaconda/root/envs/PUI2016_Python2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (19,22,23,25,63,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#read files\n",
    "dfman = pd.read_csv(PUIdata + '/BORO_zip_files_csv/MN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCitiBikeCSV(datestring):\n",
    "    print (\"Downloading\", datestring)\n",
    "    ### First I will check that it is not already there\n",
    "    if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.csv\"):\n",
    "        if os.path.isfile(datestring + \"-citibike-tripdata.csv\"):\n",
    "            # if in the current dir just move it\n",
    "            if os.system(\"mv \" + datestring + \"-citibike-tripdata.csv \" + os.getenv(\"PUIDATA\")):\n",
    "                print (\"Error moving file!, Please check!\")\n",
    "        #otherwise start looking for the zip file\n",
    "        else:\n",
    "            if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.zip\"):\n",
    "                if not os.path.isfile(datestring + \"-citibike-tripdata.zip\"):\n",
    "                    os.system(\"curl -O https://s3.amazonaws.com/tripdata/\" + datestring + \"-citibike-tripdata.zip\")\n",
    "                ###  To move it I use the os.system() functions to run bash commands with arguments\n",
    "                os.system(\"mv \" + datestring + \"-citibike-tripdata.zip \" + os.getenv(\"PUIDATA\"))\n",
    "            ### unzip the csv \n",
    "            os.system(\"unzip \" + os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.zip\")\n",
    "            ## NOTE: old csv citibike data had a different name structure. \n",
    "            if '2014' in datestring:\n",
    "                os.system(\"mv \" + datestring[:4] + '-' +  datestring[4:] + \n",
    "                          \"\\ -\\ Citi\\ Bike\\ trip\\ data.csv \" + datestring + \"-citibike-tripdata.csv\")\n",
    "            os.system(\"mv \" + datestring + \"-citibike-tripdata.csv \" + os.getenv(\"PUIDATA\"))\n",
    "    ### One final check:\n",
    "    if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.csv\"):\n",
    "        print (\"WARNING!!! something is wrong: the file is not there!\")\n",
    "\n",
    "    else:\n",
    "        print (\"file in place, you can continue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 201503\n",
      "file in place, you can continue\n"
     ]
    }
   ],
   "source": [
    "datestring = '201503'\n",
    "getCitiBikeCSV(datestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gws/open/NYCOpenData/nycopendata/data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening files from cusp data facility\n",
    "DFdata = os.getenv(\"DFDATA\")\n",
    "DFdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMONTH</th>\n",
       "      <th>INCIDENTCLASSIFICATION</th>\n",
       "      <th>INCIDENTBOROUGH</th>\n",
       "      <th>INCIDENTCOUNT</th>\n",
       "      <th>AVERAGERESPONSETIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>INCIDENTCLASSIFICATION</td>\n",
       "      <td>INCIDENTBOROUGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVERAGERESPONSETIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200907.0</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Citywide</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>3:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200907.0</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>435.0</td>\n",
       "      <td>4:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200907.0</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200907.0</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEARMONTH  INCIDENTCLASSIFICATION  INCIDENTBOROUGH  INCIDENTCOUNT  \\\n",
       "0        NaN  INCIDENTCLASSIFICATION  INCIDENTBOROUGH            NaN   \n",
       "1   200907.0        Structural Fires         Citywide         1947.0   \n",
       "2   200907.0        Structural Fires        Manhattan          435.0   \n",
       "3   200907.0        Structural Fires            Bronx          432.0   \n",
       "4   200907.0        Structural Fires    Staten Island           90.0   \n",
       "\n",
       "   AVERAGERESPONSETIME  \n",
       "0  AVERAGERESPONSETIME  \n",
       "1                 3:54  \n",
       "2                 4:00  \n",
       "3                 3:59  \n",
       "4                 4:34  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check path from terminal\n",
    "data = pd.read_csv(DFdata + '/j34j-vqvt/1409875200/j34j-vqvt.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEARMONTH                  True\n",
       "INCIDENTCLASSIFICATION    False\n",
       "INCIDENTBOROUGH           False\n",
       "INCIDENTCOUNT              True\n",
       "AVERAGERESPONSETIME       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for columns with null values\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEARMONTH                 43\n",
       "INCIDENTCLASSIFICATION     0\n",
       "INCIDENTBOROUGH            0\n",
       "INCIDENTCOUNT              1\n",
       "AVERAGERESPONSETIME        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check number of null values per column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEARMONTH                 False\n",
       "INCIDENTCLASSIFICATION    False\n",
       "INCIDENTBOROUGH           False\n",
       "INCIDENTCOUNT             False\n",
       "AVERAGERESPONSETIME       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.dropna()\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEARMONTH                 float64\n",
       "INCIDENTCLASSIFICATION     object\n",
       "INCIDENTBOROUGH            object\n",
       "INCIDENTCOUNT             float64\n",
       "AVERAGERESPONSETIME        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dtype\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/anaconda/root/envs/PUI2016_Python2/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/rh/anaconda/root/envs/PUI2016_Python2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#change to int\n",
    "df['YEARMONTH'] = df['YEARMONTH'].astype(int)\n",
    "df['INCIDENTCOUNT'] = df['INCIDENTCOUNT'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIGURE OUT DATETIME !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMONTH</th>\n",
       "      <th>INCIDENTCLASSIFICATION</th>\n",
       "      <th>INCIDENTBOROUGH</th>\n",
       "      <th>INCIDENTCOUNT</th>\n",
       "      <th>AVERAGERESPONSETIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200907</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Citywide</td>\n",
       "      <td>1947</td>\n",
       "      <td>3:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200907</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>435</td>\n",
       "      <td>4:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200907</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>432</td>\n",
       "      <td>3:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200907</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>90</td>\n",
       "      <td>4:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200907</td>\n",
       "      <td>Structural Fires</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>652</td>\n",
       "      <td>3:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEARMONTH INCIDENTCLASSIFICATION INCIDENTBOROUGH  INCIDENTCOUNT  \\\n",
       "1     200907       Structural Fires        Citywide           1947   \n",
       "2     200907       Structural Fires       Manhattan            435   \n",
       "3     200907       Structural Fires           Bronx            432   \n",
       "4     200907       Structural Fires   Staten Island             90   \n",
       "5     200907       Structural Fires        Brooklyn            652   \n",
       "\n",
       "  AVERAGERESPONSETIME  \n",
       "1                3:54  \n",
       "2                4:00  \n",
       "3                3:59  \n",
       "4                4:34  \n",
       "5                3:29  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'YEAR': pd.to_datetime(df['YEARMONTH']).dt.year,\n",
    "    'MONTH': pd.to_datetime(df['YEARMONTH']).dt.month})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge df\n",
    "\n",
    "DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False)[source]\n",
    "\n",
    "A.merge(B, left_on='lkey', right_on='rkey', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rows that were lost in the merge\n",
    "ms[~ms['Country'].isin(df_['Country'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fedhere/PUI2017_fb55/blob/master/HW5_fb55/Assignment3_solution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['haircolor'] = df['haircolor'].replace({'Brown':1, 'Blonde':2, 'Black':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting columns to numeric values and throwing away \n",
    "s = dfen['Site EUI(kBtu/ft2)'] #extract Site EUI as series\n",
    "ss = pd.to_numeric(s, errors='coerce')  # convert strings to float, use errors=coerce to set missing values to nan\n",
    "dfen['Site EUI(kBtu/ft2)'] = ss\n",
    "##check that your conversion worked: e.g.\n",
    "print (dfen['Site EUI(kBtu/ft2)'].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add reading JSON\n",
    "import sys\n",
    "import json\n",
    "try:\n",
    "    import urllib2 as urllib\n",
    "except ImportError:\n",
    "    import urllib.request as urllib\n",
    "\n",
    "\n",
    "def get_jsonparsed_data(url):\n",
    "    \"\"\"\n",
    "    from http://stackoverflow.com/questions/12965203/how-to-get-json-from-webpage-into-python-script\n",
    "    Receive the content of ``url``, parse it as JSON and return the object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "    \"\"\"\n",
    "    response = urllib.urlopen(url)\n",
    "    data = response.read().decode(\"utf-8\")\n",
    "    return json.loads(data)\n",
    "jsonData = get_jsonparsed_data(\\\n",
    "                    \"https://serv.cusp.nyu.edu/~fbianco/PUI2017/data/cityWeather.json\")\n",
    "jsonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add reading API\n",
    "\n",
    "#Read MTA API\n",
    "\n",
    "if not len(sys.argv) == 4:\n",
    "\tprint (\"Invalid number of arguments. Run as: python show_bus_locations_rxl204.py <MTA_KEY> <BUS_LINE> <BUS_LINE.csv>\")\n",
    "\tsys.exit()\n",
    "\n",
    "url = \"http://bustime.mta.info/api/siri/vehicle-monitoring.json?key=\" + sys.argv[1] + \"&VehicleMonitoringDetailLevel=calls&LineRef=\" + sys.argv[2]\n",
    "\n",
    "response = urllib.urlopen(url)\n",
    "data = response.read().decode(\"utf-8\")\n",
    "data = json.loads(data)\n",
    "\n",
    "#Opens a file for writing\n",
    "fout = open(sys.argv[3],\"w\")\n",
    "fout.write(\"Latitude,Longitude,Stop Name,Stop Status\\n\")\n",
    "\n",
    "Bus_Count = len(data['Siri']['ServiceDelivery']['VehicleMonitoringDelivery'][0]['VehicleActivity'])\n",
    "\n",
    "for i in (range(0,Bus_Count)):\n",
    "\tBus_Lat = data['Siri']['ServiceDelivery']['VehicleMonitoringDelivery'][0]['VehicleActivity'][i]['MonitoredVehicleJourney']['VehicleLocation']['Latitude']\n",
    "\tBus_Long = data['Siri']['ServiceDelivery']['VehicleMonitoringDelivery'][0]['VehicleActivity'][i]['MonitoredVehicleJourney']['VehicleLocation']['Longitude']\n",
    "\tif data['Siri']['ServiceDelivery']['VehicleMonitoringDelivery'][0]['VehicleActivity'][i]['MonitoredVehicleJourney']['OnwardCalls']=={}:\n",
    "\t\tStop_Name='NA'\n",
    "\telse: \n",
    "\t\tStop_Name = data['Siri']['ServiceDelivery']['VehicleMonitoringDelivery'][0]['VehicleActivity'][i]['MonitoredVehicleJourney']['OnwardCalls']['OnwardCall'][0]['StopPointName']\n",
    "\tif data['Siri']['ServiceDelivery']['VehicleMonitoringDelivery'][0]['VehicleActivity'][i]['MonitoredVehicleJourney']['OnwardCalls']=={}:\n",
    "\t\tStop_Status='NA'\n",
    "\telse: \n",
    "\t\tStop_Status = data['Siri']['ServiceDelivery']['VehicleMonitoringDelivery'][0]['VehicleActivity'][i]['MonitoredVehicleJourney']['OnwardCalls']['OnwardCall'][0]['Extensions']['Distances']['PresentableDistance'] \n",
    "\n",
    "\tfout.write(\"%s,%s,%s,%s\\n\" %(Bus_Lat, Bus_Long, Stop_Name, Stop_Status))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stating the Null Hypothesis: The bus rerouting does not change the average travel time.\n",
    "\n",
    "$H_0$: TimeNew.mean() >= TimeOld.mean()\n",
    "\n",
    "$H_a$: TimeNew.mean() < TimeOld.mean()\n",
    "\n",
    "$\\alpha=0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = \\frac{\\mu_{pop} - \\mu_{sample}}{\\sigma / \\sqrt{N}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculating z-scores\n",
    "# here it is ok to use either the stdev from timesOld or from timesNew\n",
    "z = (timesOldMean - timesNew.mean()) / (timesOldStd / np.sqrt(len(timesNew)))\n",
    "print(\"The Z statistics is Z = {0:.2f}\".format(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z score for Bus X8 rerouting: 2.6\n",
    "This means we are 2.6 standard deviations away\n",
    "from the mean of the old trip duration\n",
    "\n",
    "The Null Hypothesis that the new route makes commuting time worse\n",
    "IS REJECTED at the 95.0% significance level (p<0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deciding on statistical test\n",
    "2 samples, categorical data\n",
    "TWO OPTIONS z test, or chi square test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z TEST\n",
    "the z test compares the standard deviation of the expected distribution and the observed result. it tells you literally how many standard deviations from the tail an observation is, under the _assumption of normality\n",
    "must define the sample standard deviation\n",
    "standard deviation of the sampling distribution the distribution is Binomial, the binomail stdev is\n",
    "(see a proof here!: http://stats.stackexchange.com/questions/29641/standard-error-for-the-mean-of-a-sample-of-binomial-random-variables!):\n",
    "$\\sqrt{\\frac{p(1 - p)}{n}}$\n",
    "for 2 samples this becomes\n",
    "$\\sqrt{ \\frac{ \\hat{p}(1 - \\hat{p})} {n1} + \\frac{ \\hat{p}(1 - \\hat{p})} {n1} }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-tests are statistical calculations that can be used to compare population means to a sample's. The z-score tells you how far, in standard deviations, a data point is from the mean or average of a data set. A z-test compares a sample to a defined population and is typically used for dealing with problems relating to large samples (n > 30). Z-tests can also be helpful when we want to test a hypothesis. Generally, they are most useful when the standard deviation is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ztest = (tOldMean -tNew.mean())/(tOldStdev/len(df)**0.5)\n",
    "print (ztest)\n",
    "#population mean - sample mean / std/sqrt of pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z score for Bus X8 rerouting: 2.6\n",
    "This means we are 2.6 standard deviations away\n",
    "from the mean of the old trip duration\n",
    "\n",
    "\n",
    "The Null Hypothesis that the new route makes commuting time worse\n",
    "IS REJECTED at the 95.0% significance level (p<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test standard deviation error: 0.032\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "#we like fractions better then percentages. as a rule of thumb, either use fractions or counts\n",
    "P_0 = 3.5 * 0.01 \n",
    "P_1 = 70.1 * 0.01\n",
    "\n",
    "n_0 = 409\n",
    "n_1 = 564\n",
    "\n",
    "#lets get the counts by multiplying by the sample size\n",
    "Nt_0 = P_0 * n_0\n",
    "Nt_1 = P_1 * n_1\n",
    "\n",
    "#depending on distribution, calculate standard error\n",
    "sp_stdev = lambda p, n: np.sqrt( p * ( 1 - p ) / n[0] +  p * ( 1 - p ) / n[1]  )\n",
    "sp_stdev_2y = sp_stdev((Nt_0 + Nt_1) / (n_0 + n_1), [n_0, n_1])\n",
    "print ( \"test standard deviation error: %.3f\"%sp_stdev_2y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z score for 1-3 years \"ever employed in CEO jobs\": z = 20.770\n"
     ]
    }
   ],
   "source": [
    "#calculate z-score\n",
    "zscore = lambda p0, p1, s : (p0 - p1) / s\n",
    "z_2y = zscore(P_1, P_0, sp_stdev_2y)\n",
    "print ('z score for 1-3 years \"ever employed in CEO jobs\": z = %.3f'%z_2y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if $p&lt;\\alpha$ : reject H0 **\n",
    "IMPORTANT!! note that this P in the bottom line of the table is not the p-value, but\n",
    "p-value = 1-P\n",
    "\n",
    "Since p_2y = 1 - 0.9998 = 0.00 is smaller than the critical value of 0.05, the null hypothesis is rejected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#get the corresponding p-value by looking up the table: z score of 0.83-> 0.7967 \n",
    "\n",
    "1-0.7967 > 0.05\n",
    "\n",
    "Since the p value of 0.2 is not smaller than the critical value 0.05, the null hypothesis is not rejected. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T test\n",
    "t-tests are calculations used to test a hypothesis, but they are most useful when we need to determine if there is a statistically significant difference between two independent sample groups. In other words, a t-test asks whether a difference between the means of two groups is unlikely to have occurred because of random chance. Usually, t-tests are most appropriate when dealing with problems with a limited sample size (n < 30)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi Square Test \n",
    "$\\chi^2$ test\n",
    "the chisq statistics tests a number against the distribution of the following quantity:\n",
    "$$\\chi^2 = \\Sigma \\frac{(observation - expectation)^2}{expectation}$$\n",
    "if we talk about sample fractions that is\n",
    "$$\\chi^2 = \\Sigma \\frac{(f_{observed} - f_{expectated})^2}{f_{expected}}$$\n",
    "turns out this quantity is distributed according to a chi square distribution, so if i get the $\\chi^2$ statistics i can compare it to the full chisq distribution and see how far in the tail it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evalChisq(values):\n",
    "    '''Evaluates the chi sq from a contingency value\n",
    "    Arguments:\n",
    "    values: 2x2 array or list, the contingengy table\n",
    "    '''\n",
    "    if not (len(values.shape) == 2 and values.shape == (2,2)):\n",
    "        print (\"must pass a 2D array\")\n",
    "        return -1\n",
    "    values = np.array(values)\n",
    "    E = np.empty_like(values)\n",
    "    for j in range(len(values[0])):\n",
    "        for i in range(2):\n",
    "            \n",
    "            E[i][j] = ((values[i,:].sum() * values[:,j].sum()) / \n",
    "                        (values).sum())\n",
    "    return ((values - E)**2 / E).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi sq statistics for \"ever employed in CEO jobs\": chisq = 436.223, DOF = 1\n"
     ]
    }
   ],
   "source": [
    "sample_values_ceojob  = np.array([[0.701 * 564, 0.299 * 564], [0.0305 * 409, 0.965 * 409]])\n",
    "\n",
    "chisq_ceojob = evalChisq(sample_values_ceojob)\n",
    "DOF = len(sample_values_ceojob) - 1\n",
    "print ('chi sq statistics for \"ever employed in CEO jobs\": '+\n",
    "       'chisq = {:.3f}, DOF = {:d}'.format(chisq_ceojob, DOF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Null hypothesis that the program does not affect CEO employability, \n",
      "measured as: the inmates not participating in the program are employed in CEO jobs \n",
      "in an equal or higher percentage within 1-3 years of release\n",
      "can be rejected at alpha = 0.05\n",
      "with a chi square statistics of 436.22\n"
     ]
    }
   ],
   "source": [
    "chimin_alpha5pc = 3.84\n",
    "print (\"The Null hypothesis that the program does not affect CEO employability, \")\n",
    "print (\"measured as: the inmates not participating in the program are employed in CEO jobs \")\n",
    "print (\"in an equal or higher percentage within 1-3 years of release\")\n",
    "if chisq_ceojob > chimin_alpha5pc :\n",
    "    print (\"can be rejected at alpha = 0.05\")\n",
    "else: \n",
    "    print (\"cannot be rejected (p<0.05)\")\n",
    "print (\"with a chi square statistics of %.2f\"%chisq_ceojob )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the chisquare statistic of 436.22 is more than the 3.84, the null hypothesis can be rejected at alpha = 0.05. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS tests to compare 2 samples\n",
    "http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ks_2samp.html\n",
    "\n",
    "scipy.stats.ks_2samp(data1, data2)[source]\n",
    "\n",
    "Null: the two distribution come from the same parent distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks = scipy.stats.ks_2samp(df.dayduration, df.nightduration)\n",
    "print (ks)\n",
    "if ks[1] >= alpha: \n",
    "    print (\"The Null hypothesis that the two samples are generated \" + \n",
    "            \"by the same parent distribution cannot be rejected (p>=0.05)\")\n",
    "else: \n",
    "    print (\"The Null hypothesis that the two samples are generated \" + \n",
    "            \"by the same parent distribution is rejected (p<0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "Now retest using a test for correlation.\n",
    "That will answer a slightly different question though - formulate the NULL appropriately. The tests for correlations (generally) requires the variable to be paired, so that I can tell if x changes does y change similarly. But the datasets are of different size! You will need to reduce them to the same size. You can do that by subsampling of the data: take only 1 ride every of 200, which you can achieve \"slicing and broadcasting\" the array or using one of the python function (built in python numpy.random.choice() functions for example: Docstring: choice(a, size=None, replace=True, p=None)\n",
    "Generates a random sample from a given 1-D array\n",
    ".. versionadded:: 1.7.0\n",
    "\n",
    "Parameters ...\n",
    "But make sure you understand how to use it! there is an option \"replace\" which you should think about. Pearson's test for correlation¶\n",
    "notice that the Pearson's is a pairwise test: the samples need to be a. the same size b. sorted! (how??)\n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr\n",
    "Hypothesis\n",
    "H0: There is no strong relationship between trip duration for day and night riders\n",
    "Pearson's test for correlation\n",
    "scipy.stats.pearsonr(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#more rides during the day than during the night: subsample day rides\n",
    "dfday = cb2015[cb2015.dayride].iloc[np.random.choice(range(len(cb2015[cb2015.dayride])), (~cb2015.dayride).sum(), \n",
    "                                      replace=False)]\n",
    "\n",
    "#or\n",
    "\n",
    "df['dayduration'].dropna(inplace= True)\n",
    "df['nightduration'].dropna(inplace= True)\n",
    "\n",
    "#select one trip from every 200\n",
    "df3 = df[df.index % 100 == 0]\n",
    "df3.head()\n",
    "\n",
    "X = df3.dayduration\n",
    "Y = df3.nightduration\n",
    "\n",
    "pr = scipy.stats.pearsonr(X, Y)\n",
    "print (pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from Pearson's correlation indicates that there is no correlation in trip durations between daytime and nighttime riders.\n",
    "Pearson's correlation coefficient between two variables is defined as the covariance of the two variables divided by the product of their standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spr = scipy.stats.spearmanr(X, Y)\n",
    "print(spr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman's r test result SpearmanrResult(correlation=0.99999921875810915, pvalue=0.0)\n",
    "The Null hypothesis that the two samples are generated from uncorrelated distributions. is rejected (p = 0.000<0.05)\n",
    "This test is often used to assess if sample are generated by the same distribution but in fact it tests if the samples are generated by correlated distributions. As a test to assess independence it is not powerful, as even a small amount of correlation would raise the p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smf.ols(formula = 'BBL ~ Postcode + Longitude + I(Postcode**2)', data = test3.fit(). summary()\n",
    "#I dimensionality matrix\n",
    "        \n",
    "lm = smf.ols(formula='y ~ x', data=dfjoin).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting matplotlib: \n",
    "        https://www.datascience.com/learn-data-science/tutorials/creating-data-visualizations-matplotlib-data-science-python  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Error Bars\n",
    "\n",
    "The Scatter Plots with Error Bars procedure extends the capability of the basic scatter plot by allowing you to plot\n",
    "the variability in Y and X corresponding to each point. Each point on the plot represents the mean or median of\n",
    "one or more values for Y and X within a subgroup. \n",
    "\n",
    "The error bars may represent the standard\n",
    "deviation (SD) of the data, the standard error of the mean (SE), a confidence interval, the data range, or\n",
    "percentiles.\n",
    "\n",
    "Axes.errorbar(x, y, yerr=None, xerr=None, fmt='', ecolor=None, elinewidth=None, capsize=None, barsabove=False, lolims=False, uplims=False, xlolims=False, xuplims=False, errorevery=1, capthick=None, *, data=None, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plotting scatter with error bars\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(df_.gdp * 1e-12, df_['Number of mass shootings'])\n",
    "ax.errorbar(df_.gdp * 1e-12, df_['Number of mass shootings'], \n",
    "            yerr = np.sqrt(df_['Number of mass shootings'] * 1.0), fmt = '.')\n",
    "ax.set_xlabel(\"GDP (in tillion $)\")\n",
    "ax.set_ylabel(\"Number of mass shooting per person\")\n",
    "ax.set_ylim();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linspace.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plotting \n",
    "scatter plots \n",
    "zoomed scatter\n",
    "histogram \n",
    "bar plot \n",
    "seaborn scatter matrix\n",
    "line fitting plots (models) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "fit a line to the Number of mass shootings per person as a function of Average total all civilian firearms per person. Before you do it it is a good idea to make sure that both quantities are roughly of the same order of magnitude (unity). Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_['x'] = df_[u'Average total all civilian firearms'] / df_['pop'] * 10\n",
    "df_['y'] = df_[u'Number of mass shootings'] / df_['pop'] * 1e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation\n",
    "scipy.stats.pearsonr(x, y)[source]\n",
    "Calculates a Pearson correlation coefficient and the p-value for testing non-correlation.\n",
    "\n",
    "The Pearson correlation coefficient measures the linear relationship between two datasets. Strictly speaking, Pearson’s correlation requires that each dataset be normally distributed. Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact linear relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.\n",
    "\n",
    "The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Pearson correlation at least as extreme as the one computed from these datasets. The p-values are not entirely reliable but are probably reasonable for datasets larger than 500 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manhattan = cb2015[cb2015.M].iloc[np.random.choice(range(len(cb2015[cb2015.M])), (cb2015.BK).sum(), \n",
    "                                      replace=False)]\n",
    "parsons = scipy.stats.pearsonr(np.sort(manhattan.tripduration), np.sort(cb2015[cb2015.BK].tripduration))\n",
    "print (\"Parson's test result\", parsons)\n",
    "if parsons[1] >= alpha: \n",
    "    print (r\"The Null hypothesis that the two samples are generated from uncorrelated distributions. \" + \n",
    "           \"cannot be rejected (p>=0.05)\")\n",
    "else: \n",
    "    print (\"The Null hypothesis that the two samples are generated from uncorrelated distributions. \" + \n",
    "           \"is rejected (p = %.3f<0.05)\"%parsons[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spearman Correlation\n",
    "\n",
    "scipy.stats.spearmanr(a, b=None, axis=0)[source]\n",
    "Calculates a Spearman rank-order correlation coefficient and the p-value to test for non-correlation.\n",
    "\n",
    "The Spearman correlation is a nonparametric measure of the monotonicity of the relationship between two datasets. Unlike the Pearson correlation, the Spearman correlation does not assume that both datasets are normally distributed. Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact monotonic relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.\n",
    "\n",
    "The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Spearman correlation at least as extreme as the one computed from these datasets. The p-values are not entirely reliable but are probably reasonable for datasets larger than 500 or so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta1 = cor[0] * df_.y.std() / df_.x.std()\n",
    "beta0 = df_.y.mean() - beta1 * df_.x.mean()\n",
    "\n",
    "fig = pl.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "df_.plot.scatter(x=\"x\", y=\"y\", ax=ax)\n",
    "ax.plot(df_.x, beta0 + beta1 * df_.x, '-', color='k', label=\"analytical\")\n",
    "ax.set_ylabel(\"Number of mass shootings per person (x 10,000,000)\")\n",
    "ax.set_xlabel(\"Average civilian fire arms per person\")\n",
    "pl.legend()\n",
    "print (\"coefficients from analytical solution\", beta0, beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polyfit \n",
    "numpy.polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False)[source]\n",
    "Least squares polynomial fit.\n",
    "\n",
    "Fit a polynomial p(x) = p[0] * x**deg + ... + p[deg] of degree deg to points (x, y). Returns a vector of coefficients p that minimises the squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polyfit_coeffs = np.polyfit(df_['x'], df_['y'], 1)\n",
    "\n",
    "fig = pl.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "df_.plot.scatter(x=\"x\", y=\"y\", ax=ax)\n",
    "ax.plot(df_.x, polyfit_coeffs[0] + polyfit_coeffs[1] * df_.x, '-', color='DarkOrange', label=\"polyfit\")\n",
    "ax.set_ylabel(\"Number of mass shootings per person (x 10,000,000)\")\n",
    "ax.set_xlabel(\"Average civilian fire arms per person\")\n",
    "pl.legend()\n",
    "print (\"polyfit coefficients:\", polyfit_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels OLS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelOLS = st.OLS(exog=st.add_constant(df_.x), endog=df_.y).fit()\n",
    "\n",
    "fig = pl.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "df_.plot.scatter(x=\"x\", y=\"y\", ax=ax)\n",
    "ax.plot(df_.x, polyfit_coeffs[1] + polyfit_coeffs[0] * df_.x, '-', color='DarkOrange', label=\"polyfit\")\n",
    "ax.plot(df_.x, modelOLS.fittedvalues, color=\"DarkGreen\", label=\"OLS\")\n",
    "ax.set_ylabel(\"Number of mass shootings per person (x 10,000,000)\")\n",
    "ax.set_xlabel(\"Average civilian fire arms per person\")\n",
    "pl.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel WLS\n",
    "Note: when the number of mass shootings is 0 the error is 0. But 0 errros cannot be used as weight (cause 1/0 = infinity). Thus I am setting the error on the values Nmassshootings = 0 to 1, which is the uncertainty on Nmassshootings = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_['yerr'] = np.sqrt(df_[u'Number of mass shootings'] \n",
    "                             / df_['pop'] * 1e7) + 1\n",
    "df_.w = 1.0 / df_.yerr\n",
    "\n",
    "\n",
    "modelWLS = st.WLS(exog=st.add_constant(df_.x), endog=df_.y,\n",
    "      weights = 1.0/df_.w).fit()\n",
    "\n",
    "fig = pl.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "df_.plot.scatter(x=\"x\", y=\"y\", yerr=df_.yerr, ax=ax)\n",
    "ax.plot(df_.x, polyfit_coeffs[1] + polyfit_coeffs[0] * df_.x, '-', color='DarkOrange', label=\"polyfit\")\n",
    "ax.plot(df_.x, modelOLS.fittedvalues, color=\"DarkGreen\", label=\"OLS\")\n",
    "ax.plot(df_.x, modelWLS.fittedvalues, '-', color='IndianRed', label=\"WLS\")\n",
    "ax.set_ylabel(\"Number of mass shootings per person (x 10,000,000)\")\n",
    "ax.set_xlabel(\"Average civilian fire arms per person\")\n",
    "pl.legend()\n",
    "print (\"WLS coefficients:\",  modelWLS.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelWLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attempted to use reverse geocode, but met with GeoCoderService Error due to too many requests\n",
    "#alternative method: approximate boundaries for Manhattan and Brookyln using boundingbox\n",
    "lat_min = 40.694197\n",
    "lon_max = -73.896398\n",
    "\n",
    "def borough_sort(lat_lon): #bounding \"Manhattan\" into a rough box, assuming everything outside \"Manhattan\" is \"BKLYN\"\n",
    "    lat, lon = lat_lon\n",
    "    if ((lat >= lat_min) & (lon <= lon_max)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reverse geocoding \n",
    "#this cells reverse geocodes coordinates to zip codes\n",
    "county = np.array([''] * len(cb2015))\n",
    "#my API is saved as an environmental variable\n",
    "#gAPI = os.getenv('GOOGLEAPI')\n",
    "#my API saved in a local file as gAPI = 'XXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "from gAPI import gAPI\n",
    "for i,ll in enumerate(pd.DataFrame(latlon).drop_duplicates().values):\n",
    "    print (\"%d/%d\"%(i, nstations))\n",
    "    url = (\"https://maps.googleapis.com/maps/api/geocode/json?latlng=\" +\n",
    "           \"%f,%f&key=%s\"%(\n",
    "            ll[0], ll[1], gAPI))\n",
    "    #print (\"https://maps.googleapis.com/maps/api/geocode/json?latlng=\" +\n",
    "    #       \"%f,%f&key=%s\"%(\n",
    "    #        ll[0], ll[1], os.getenv('GOOGLEAPI')))\n",
    "    #print (get_jsonparsed_data(url)[\"results\"][0]['address_components'][4])\n",
    "    # for testing break loop after N\n",
    "    #if i>10: break\n",
    "    revgeo = get_jsonparsed_data(url)[\"results\"][0]['address_components'][4]\n",
    "    #print (revgeo)\n",
    "    county[(latlon[:,0] == ll[0]) * \n",
    "           (latlon[:,1] == ll[1])] = revgeo['long_name']\n",
    "cb2015['county'] = county\n",
    "cb2015.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rxl204/PUI2017_rxl204/blob/master/HW4_rxl204/Assignment4.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fitting a line\n",
    "p1, p0, linmodel_1 = fit_line1(np.log10(bblnrgdataCut.UnitsTotal), \n",
    "                        np.log10(bblnrgdataCut.nrg))\n",
    "pl.figure(figsize=(10,10))\n",
    "pl.scatter(np.log10(bblnrgdataCut.UnitsTotal), np.log10(bblnrgdataCut.nrg))\n",
    "plot(np.log10(bblnrgdataCut.UnitsTotal), linmodel_1.predict(), 'k')\n",
    "xl = pl.xlabel(\"log10 Number of Units in Building\", fontsize=20)\n",
    "yl = pl.ylabel(\"building log10 Energy consumption per (kBtu)\", fontsize=20)\n",
    "linmodel_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## polynomial fit\n",
    "#I find the easiest way to use the formula package is to use a dataframe \n",
    "#with the quantities that are not linear already calculated\n",
    "\n",
    "bblnrgdataCut['logNrg']  = np.log10(bblnrgdataCut.nrg)\n",
    "bblnrgdataCut['logUnits']  = np.log10(bblnrgdataCut.UnitsTotal)\n",
    "\n",
    "X = np.linspace(bblnrgdataCut['logUnits'].min(), bblnrgdataCut['logUnits'].max(), 1000)\n",
    "curvemodel = smf.ols(formula = 'logNrg ~ logUnits + I(logUnits**2)', \n",
    "                          data = bblnrgdataCut).fit()\n",
    "pl.figure(figsize=(16,14))\n",
    "pl.scatter(np.log10(bblnrgdataCut.UnitsTotal), np.log10(bblnrgdataCut.nrg))\n",
    "plot(X, curvemodel.predict(exog = dict(logUnits = X)), 'k')\n",
    "xl = pl.xlabel(\"log10 Number of Units in Building\", fontsize=20)\n",
    "yl = pl.ylabel(\"building log10 Energy consumption per (kBtu)\", fontsize=20)\n",
    "curvemodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fedhere/PUI2017_fb55/blob/master/HW6_fb55/building_nrg_solution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import mpld3\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(df_.gdp * 1e-12, df_['Number of mass shootings'])\n",
    "ax.errorbar(df_.gdp * 1e-12, df_['Number of mass shootings'], \n",
    "            yerr = np.sqrt(df_['Number of mass shootings'] * 1.0), fmt = '.')\n",
    "ax.set_xlabel(\"GDP (in tillion $)\")\n",
    "ax.set_ylabel(\"Number of mass shooting per person\")\n",
    "ax.set_ylim();\n",
    "#labels = ['{0}, {1}'.format(c, n) for c,n in zip(df_[\"Country\"].values, \n",
    "#                                                 df_[\"Number of mass shootings\"].values)]\n",
    "#tooltip = mpld3.plugins.PointLabelTooltip(scatter, labels=labels)\n",
    "#mpld3.plugins.connect(fig, tooltip)\n",
    "#mpld3.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checking for outliers\n",
    "df_[df_.gdp > 10e12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_[df_[\"Number of mass shootings\"] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
